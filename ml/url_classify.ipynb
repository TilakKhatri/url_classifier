{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1d1690be-a519-4d62-a76f-3346b3965a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy.sparse import csr_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import (\n",
    "    classification_report, \n",
    "    confusion_matrix, \n",
    "    roc_curve, \n",
    "    roc_auc_score,\n",
    "    precision_recall_curve,\n",
    "    average_precision_score\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957407fa-0fe5-4963-81fd-7b6f3fb59fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = './sample_data/data.csv'\n",
    "url_csv =  pd.read_csv(url)\n",
    "url_csv.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c33b5aa-553f-474d-85d7-f4a53d11daea",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_df = pd.DataFrame(url_csv)\n",
    "url_df = np.array(url_df)  \n",
    "\n",
    "label =  [d[1] for d in url_df]\n",
    "urls = [d[0] for d in url_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8e5713f0-65bb-42c0-a49e-c8ba346beaae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanitization(web):\n",
    "    web = web.lower()\n",
    "    token = []\n",
    "    dot_token_slash = []\n",
    "    raw_slash = str(web).split('/')\n",
    "    for i in raw_slash:\n",
    "        # removing slash to get token\n",
    "        raw1 = str(i).split('-')\n",
    "        slash_token = []\n",
    "        for j in range(0,len(raw1)):\n",
    "            # removing dot to get the tokens\n",
    "            raw2 = str(raw1[j]).split('.')\n",
    "            slash_token = slash_token + raw2\n",
    "        dot_token_slash = dot_token_slash + raw1 + slash_token\n",
    "    # to remove same words\n",
    "    token = list(set(dot_token_slash))  \n",
    "    if 'com' in token:\n",
    "        #remove com\n",
    "        token.remove('com')\n",
    "    return token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed71344-3ad3-4562-bee6-865a251368b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(tokenizer=sanitization)\n",
    "x = vectorizer.fit_transform(urls)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, label, test_size=0.2, random_state=42)\n",
    "\n",
    "# Model training\n",
    "lgr = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "lgr.fit(x_train, y_train)\n",
    "score = lgr.score(x_test, y_test)\n",
    "print(\"Accuracy: {0:.2f} %\".format(100 * score))\n",
    "\n",
    "# Predictions for evaluation\n",
    "y_pred = lgr.predict(x_test)\n",
    "y_pred_proba = lgr.predict_proba(x_test)[:, 1]  # probabilities for positive class\n",
    "\n",
    "# 1. Classification Report (Precision, Recall, F1-Score)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=['Good URL', 'Bad URL']))\n",
    "\n",
    "# 2. Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Good URL', 'Bad URL'], \n",
    "            yticklabels=['Good URL', 'Bad URL'])\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show()\n",
    "\n",
    "# 3. ROC Curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "\"\"\"\n",
    "# 4. Precision-Recall Curve\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_pred_proba)\n",
    "average_precision = average_precision_score(y_test, y_pred_proba)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(recall, precision, color='blue', lw=2, ve\n",
    "         label=f'Precision-Recall curve (AP = {average_precision:.2f})')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()\n",
    "\n",
    "# 5. Top 15 Important Features for Bad URLs\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "coefs = lgr.coef_[0]\n",
    "top_bad_features = sorted(zip(feature_names, coefs), key=lambda x: x[1], reverse=True)[:15]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh([x[0] for x in top_bad_features], [x[1] for x in top_bad_features], color='red')\n",
    "plt.xlabel('Coefficient Value')\n",
    "plt.title('Top 15 Important Features for Bad URLs')\n",
    "plt.gca().invert_yaxis()  # highest coefficient at top\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\"\"\"\n",
    "vectorizer_save = vectorizer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
